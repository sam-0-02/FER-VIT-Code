# FaceEmotionRestoration-ViT-GFPGAN

This repository contains the official code and resources for the paper:

**"Quality-aware facial emotion recognition using Vision Transformers with GFPGAN-based image restoration"**

---

## ğŸ“Œ Overview
Facial emotion recognition (FER) models are highly sensitive to image quality.  
This project proposes a **quality-aware pipeline** that:
1. Degrades face images synthetically to simulate real-world distortions (noise, blur, compression).  
2. Restores low-quality faces using **GFPGAN** (Generative Facial Prior GAN).  
3. Classifies emotions with a **Vision Transformer (ViT)** trained on the FER-2013 dataset.  
4. Evaluates the effect of restoration on classification accuracy and robustness.  

---

## ğŸ“‚ Repository Structure
FER-VIT-Code/
â”‚â”€â”€ README.md                       
â”‚â”€â”€ LICENSE                         
â”‚â”€â”€ requirements.txt                
â”‚â”€â”€ setup_instructions.md           
â”‚
â”œâ”€â”€ data/
â”‚   â”‚â”€â”€ README.md                  
â”‚   â””â”€â”€ sample_images/              
â”‚       â”œâ”€â”€ clean/
â”‚       â”œâ”€â”€ degraded/
â”‚       â””â”€â”€ restored/
â”‚
â”œâ”€â”€ pretrained_models/
â”‚   â””â”€â”€ GFPGANv1.3.pth              
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ degradation and comparision step1.py
â”‚   â”œâ”€â”€ cchecking for blur or clean image.py
â”‚   â”œâ”€â”€ GFP GAN Step 3.py
â”‚   â”œâ”€â”€ step 4 from restore to vit.py
â”‚   â”œâ”€â”€ visualization.py
â”‚



---

## ğŸ“Š Dataset
We use the **FER-2013 dataset**, available at:  
ğŸ‘‰ [FER-2013 Dataset (Kaggle)](https://www.kaggle.com/datasets/deadskull7/fer2013)

**Important:** Due to licensing restrictions, this dataset **is not redistributed in this repository**.  
Users must download it from Kaggle and arrange the folders as follows:

data/FER-2013/
â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ angry/
â”‚ â”œâ”€â”€ happy/
â”‚ â”œâ”€â”€ neutral/
â”‚ â””â”€â”€ surprise/
â””â”€â”€ test/
â”œâ”€â”€ angry/
â”œâ”€â”€ happy/
â”œâ”€â”€ neutral/
â””â”€â”€ surprise/


---

## âš™ï¸ Installation
1. Clone this repository:
   ```bash
   git clone https://github.com/sam-0-02/FER-VIT-Code.git
   cd FER-VIT-Code
 ```

2. Create and activate a virtual environment:
```
python -m venv env
source env/bin/activate   # Linux/Mac
env\Scripts\activate      # Windows
```

3. Install dependencies (tested with Python 3.10 and PyTorch 2.2.2):
```pip install -r requirements.txt```


## ğŸ’» Code Information

The src/ folder contains all scripts required to reproduce the experiments:

src/
â”œâ”€â”€ degradation and comparision step1.py      # Step 1: Apply synthetic degradation (Gaussian noise, blur, JPEG)
â”œâ”€â”€ cchecking for blur or clean image.py      # Step 2: Quality assessment (detect blurred or clean images)
â”œâ”€â”€ GFP GAN Step 3.py                         # Step 3: Restore degraded images using GFPGAN (v1.3 weights)
â”œâ”€â”€ step 4 from restore to vit.py             # Step 4: Emotion classification using ViT (trpakov/vit-face-expression)
â”œâ”€â”€ visualization.py                          # Generate ROC curves, confusion matrices, boxplots, etc.

Language: Python (tested with Python 3.10)

Frameworks: PyTorch, Hugging Face Transformers

Models used:

GFPGAN v1.3 (pretrained weights provided in pretrained_models/)

Vision Transformer (ViT) from Hugging Face (trpakov/vit-face-expression)

Execution order: Run step 1 â†’ step 2 â†’ step 3 â†’ step 4 â†’ visualization

##   ğŸš€ Usage

Run each step sequentially:

Step 1 â€“ Synthetic Degradation:
```` python src/step1_degradation.py```


Step 2 â€“ Quality Check
```python src/step2_quality_check.py```

Step 3 â€“ GFPGAN Restoration
```python src/step3_gfpgan_restore.py --weights pretrained_models/GFPGANv1.3.pth```

Step 4 â€“ Emotion Classification (ViT)
```python src/step4_vit_classification.py```

Visualization
```python src/visualization.py```


## ğŸ§ª Methodology (for reproducibility)

The pipeline follows these steps:

Degradation Simulation â€“ Gaussian noise, Gaussian blur, and JPEG compression are applied to clean FER-2013 images to create degraded samples.

Frame Quality Assessment â€“ Images are analyzed using Laplacian variance (blur) and Signal-to-Noise Ratio (SNR) to classify them as clean/problematic.

Restoration with GFPGAN â€“ Degraded faces are restored using pretrained GFPGAN (v1.3) weights.

Emotion Classification â€“ Both clean, degraded, and restored images are classified using a Vision Transformer model (trpakov/vit-face-expression).

Evaluation â€“ Metrics include PSNR, SSIM (image quality) and Accuracy, Precision, Recall, F1-score (emotion classification). Visualizations include ROC curves, confusion matrices, and probability distributions.


## ğŸ“ˆ Results

Image Quality Metrics: PSNR, SSIM

Emotion Classification Metrics: Accuracy, Precision, Recall, F1-score

Visualizations: Confusion matrices, ROC curves, probability distributions, boxplots


## ğŸ“œ Citation

If you use this repository in your work, please cite:

```Mudvari, G., Nandhini, R., et al.
"Quality-aware facial emotion recognition using Vision Transformers with GFPGAN-based image restoration."
PeerJ Computer Science, 2025 (under review).```



## ğŸ™ Acknowledgements

FER-2013 dataset: Kaggle

GFPGAN: Tencent ARC Lab

ViT model: Hugging Face â€“ trpakov/vit-face-expression


## ğŸ¤ Contribution Guidelines

Contributions are welcome!
If you wish to improve this codebase, please open an issue or submit a pull request.
